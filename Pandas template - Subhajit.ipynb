{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas \n",
    "\n",
    "> <h>1. Preparing data </h>\n",
    "\n",
    "1.1 Reading multiple datafiles\n",
    "\n",
    "1.2 Reindexing Dataframes\n",
    "\n",
    "1.3 Arithmetic with Series & DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraires\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the dataframe\n",
    "\n",
    "The primary tool we can use for data import is read_csv. This function accepts the file path of a comma-separated values(CSV) file as input and returns a panda’s data frame directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the (coverT) dataset.\n",
    "\n",
    "### START CODE HERE : \n",
    "df=pd.read_csv(\"C:\\Users\\Downloads\\coverT.csv\")\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has other convenient tools with similar default calling syntax that import various data formats into data frames:\n",
    "\n",
    "1. pd.read_excel() #for importing excel files\n",
    "2. pd.read_html() #for importing html data\n",
    "3. pd.read_json() #for importing json data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read multiple files using pandas, we generally need separate data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the datasets sepatetly (coverT and Digits1)\n",
    "\n",
    "### START CODE HERE : \n",
    "df=pd.read_csv(\"C:\\Users\\Downloads\\coverT.csv\")\n",
    "\n",
    "df1=pd.read_csv(\"C:\\Users\\Downloads\\Digits1.csv\")\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a loop\n",
    "\n",
    "It’s generally more efficient to iterate over a collection of file names. With that goal, we can create a list of filenames with the two file parts from before. We then initialize an empty list called dataframes and iterate through the list of filenames. Within each iteration we invoke read_csv to read a dataframe from a file and we append the resulting data frame to the dataframes list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the datasets (coverT and Digits1) using a loop\n",
    "\n",
    "### START CODE HERE : \n",
    "filenames = [\"C:\\Users\\Downloads\\coverT.csv\",\"C:\\Users\\Downloads\\Digits1.csv\"]\n",
    "dataframes = []\n",
    "for f in filenames:\n",
    "    dataframes.append(pd.read_csv(f))\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using glob\n",
    "\n",
    "When many file names have a similar pattern, that glob module from the Python Standard Library is very useful.\n",
    "We use the pattern sales*.csv to match any strings that start with the prefix sales and end with the suffix .csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the datasets (coverT ) using a glob\n",
    "\n",
    "### START CODE HERE : \n",
    "from glob import glob\n",
    "filenames = glob(\"C:\\Users\\Downloads\\sales*.csv\")\n",
    "dataframes = [pd.read_csv(f) for f in filenames]\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing dataframe\n",
    "\n",
    "~ Sorting dataframe with index and columns. \n",
    "\n",
    "~ Reindexing dataframe from a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe\n",
    "data = {'county': ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'], \n",
    "        'year': [2012, 2012, 2013, 2014, 2014], \n",
    "        'reports': [4, 24, 31, 2, 3]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the table(data) with columns\n",
    "\n",
    "### START CODE HERE : \n",
    "df.sort_values(by=['county'])\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting table with index\n",
    "\n",
    "### START CODE HERE : \n",
    "df.sort_index(axis=0,inplace=False, kind='quicksort',sort_remaining=True, ignore_index=False)\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the order (the index) of the rows\n",
    "\n",
    "### START CODE HERE :\n",
    "df.sort_index(axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexing from the dataframe index\n",
    "\n",
    "### START CODE HERE : \n",
    "df.reset_index(level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic with series and dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the date sets separately(sales-feb-2015.csv & sales-jan-2015.csv)\n",
    "\n",
    "### START CODE HERE :\n",
    "sales1=pd.read_csv(\"C:\\Users\\Downloads\\sales-jan-2015.csv\")\n",
    "sales2=pd.read_csv(\"C:\\Users\\Downloads\\sales-feb-2015.csv\")\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first five rows of data\n",
    "\n",
    "### START CODE HERE : \n",
    "sales1.head()\n",
    "sales2.head()\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean value of both the data set\n",
    "\n",
    "### START CODE HERE : \n",
    "sales1.mean()\n",
    "sales2.mean()\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage change to 100%\n",
    "\n",
    "### START CODE HERE : \n",
    "sales1.pct_change()\n",
    "sales2.pct_change()\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sales1 and sales2 by using the add function\n",
    "\n",
    "### START CODE HERE : \n",
    "sales1.add(sales2)\n",
    "\n",
    "### END CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
